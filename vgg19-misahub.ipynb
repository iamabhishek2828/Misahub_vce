{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9651086,"sourceType":"datasetVersion","datasetId":5894942},{"sourceId":9657626,"sourceType":"datasetVersion","datasetId":5899896}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#  importing the libraries","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom torchvision.datasets import ImageFolder\nfrom timm.models.swin_transformer import swin_base_patch4_window7_224\nfrom sklearn.metrics import balanced_accuracy_score\nimport numpy as np\nfrom tqdm import tqdm  # for loading bar\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nnum_epochs = 18\n","metadata":{"execution":{"iopub.status.busy":"2024-10-24T18:31:21.641372Z","iopub.execute_input":"2024-10-24T18:31:21.641785Z","iopub.status.idle":"2024-10-24T18:31:21.651082Z","shell.execute_reply.started":"2024-10-24T18:31:21.641737Z","shell.execute_reply":"2024-10-24T18:31:21.649530Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# loading the dataset","metadata":{}},{"cell_type":"code","source":"\n# Data Augmentation\ntrain_transform = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10),\n    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\nval_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\n# Load dataset\ntrain_dataset = ImageFolder(root='/kaggle/input/misahubdataset/Dataset/training', transform=train_transform)\nval_dataset = ImageFolder(root='/kaggle/input/misahubdataset/Dataset/validation', transform=val_transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# training the swin model on custom dataset","metadata":{}},{"cell_type":"code","source":"# Compute class weights based on training labels\nclass_weights = compute_class_weight('balanced', classes=np.unique(train_dataset.targets), y=train_dataset.targets)\nclass_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n\n# Define the model\nmodel = swin_base_patch4_window7_224(pretrained=True, num_classes=len(train_dataset.classes))\nmodel = model.to(device)\n\n# Loss function with class weights\ncriterion = nn.CrossEntropyLoss(weight=class_weights)\n\n# Optimizer\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n\n# Track the best model based on balanced accuracy\nbest_balanced_acc = 0.0\nbest_model_path = 'swin_transformer_best_model_in_the_world.pth'\n\n# Training loop\nfor epoch in range(num_epochs):\n    print(f\"\\nEpoch [{epoch+1}/{num_epochs}]\")\n\n    # Training Phase\n    model.train()\n    running_loss = 0.0\n    correct_train = 0\n    total_train = 0\n\n    train_progress = tqdm(train_loader, desc=\"Training\", leave=False)\n    for images, labels in train_progress:\n        images, labels = images.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n        _, predicted = torch.max(outputs.data, 1)\n        total_train += labels.size(0)\n        correct_train += (predicted == labels).sum().item()\n\n        train_progress.set_postfix(loss=running_loss / (train_progress.n + 1))\n\n    train_loss = running_loss / len(train_loader)\n    train_accuracy = 100 * correct_train / total_train\n\n    print(f\"Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.2f}%\")\n\n    # Validation Phase\n    model.eval()\n    running_val_loss = 0.0\n    correct_val = 0\n    total_val = 0\n    all_labels = []\n    all_preds = []\n\n    val_progress = tqdm(val_loader, desc=\"Validating\", leave=False)\n    with torch.no_grad():\n        for images, labels in val_progress:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n\n            running_val_loss += loss.item()\n\n            _, predicted = torch.max(outputs.data, 1)\n            total_val += labels.size(0)\n            correct_val += (predicted == labels).sum().item()\n\n            all_labels.extend(labels.cpu().numpy())\n            all_preds.extend(predicted.cpu().numpy())\n\n            val_progress.set_postfix(val_loss=running_val_loss / (val_progress.n + 1))\n\n    val_loss = running_val_loss / len(val_loader)\n    val_accuracy = 100 * correct_val / total_val\n    balanced_acc = balanced_accuracy_score(all_labels, all_preds)\n\n    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n    print(f\"Balanced Validation Accuracy: {balanced_acc:.4f}\")\n\n    # Check if the current model has the best balanced accuracy\n    if balanced_acc > best_balanced_acc:\n        best_balanced_acc = balanced_acc\n        torch.save(model.state_dict(), best_model_path)\n        print(f\"New best model saved with Balanced Accuracy: {best_balanced_acc:.4f}\")\n\nprint(f\"Training complete. Best Balanced Accuracy: {best_balanced_acc:.4f}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# predicting labels for test dataset","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nimport pandas as pd\nfrom tqdm import tqdm\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nfrom PIL import Image\nfrom torch.utils.data import Dataset\n\n# Custom Dataset class for your test images\nclass TestImageDataset(Dataset):\n    def __init__(self, root_dir, transform=None):\n        self.root_dir = root_dir\n        self.image_paths = [os.path.join(root_dir, fname) for fname in os.listdir(root_dir) if fname.endswith('.jpg')]\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        image = Image.open(img_path).convert('RGB')\n        if self.transform:\n            image = self.transform(image)\n        return image, img_path  # Returning image and image path\n\n# Path to test data directory\ntest_dir = '/kaggle/input/testdataset-misahub/Testing set/Images'  # Update this to your actual path\n\n# Define test data transformations\ntest_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\n# Load test dataset using the custom dataset class\ntest_dataset = TestImageDataset(root_dir=test_dir, transform=test_transform)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n\n# Manually define classes to ensure consistency with the training classes\nclasses = [\n    'Angioectasia', 'Bleeding', 'Erosion', 'Erythema', 'Foreign Body',\n    'Lymphangiectasia', 'Normal', 'Polyp', 'Ulcer', 'Worms'\n]\ntest_dataset.classes = classes\n\n# Set num_classes to match the trained model's output (in your case it's 10)\nnum_classes = 10\n\n# Load the saved model and ensure correct number of classes\nmodel = swin_base_patch4_window7_224(pretrained=False, num_classes=num_classes)\n\n# Load the model's weights\n# Load the model's weights with map_location to handle CPU-only environments\nmodel.load_state_dict(torch.load('swin_transformer_best_model_in_the_world.pth', map_location=device))\n# model = model.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\nmodel.eval()\n\n# Initialize lists to store image paths, class probabilities, and predicted classes\nimage_paths = []\nclass_probs = []\npredicted_classes = []\n\n# Prediction loop\nwith torch.no_grad():\n    test_progress = tqdm(test_loader, desc=\"Generating Predictions\")\n    for images, img_paths in test_progress:  # Now, using img_paths returned by the dataset\n        images = images.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n        \n        # Forward pass\n        outputs = model(images)\n        \n        # Apply softmax to get probabilities\n        probs = torch.softmax(outputs, dim=1)\n        \n        # Get predicted class (the one with the highest probability)\n        _, predicted = torch.max(probs, 1)\n        \n        # Store probabilities and predicted class\n        class_probs.extend(probs.cpu().numpy())\n        predicted_classes.extend(predicted.cpu().numpy())\n        image_paths.extend(img_paths)  # Directly extend the image paths\n\n# Convert predicted class indices to class names safely\npredicted_labels = []\nfor pred in predicted_classes:\n    if pred < len(test_dataset.classes):\n        predicted_labels.append(test_dataset.classes[pred])\n    else:\n        predicted_labels.append('Unknown')  # Handle any out-of-range predictions\n\n# Create a DataFrame with class probabilities and predicted labels\ncolumns = ['image_path'] + test_dataset.classes + ['predicted_class']\ndata = []\n\nfor i, image_path in enumerate(image_paths):\n    row = [image_path] + class_probs[i].tolist() + [predicted_labels[i]]\n    data.append(row)\n\noutput_df = pd.DataFrame(data, columns=columns)\n\n# Save the DataFrame to an Excel file (.xlsx)\noutput_df.to_excel('test_predictions_with_probs.xlsx', index=False)\n\nprint(\"Predictions saved to 'test_predictions_with_probs.xlsx'\")\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-24T18:31:26.418586Z","iopub.execute_input":"2024-10-24T18:31:26.419593Z","iopub.status.idle":"2024-10-24T18:31:26.427912Z","shell.execute_reply.started":"2024-10-24T18:31:26.419547Z","shell.execute_reply":"2024-10-24T18:31:26.426259Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# evaluating the model","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nimport torchvision.transforms as transforms\nfrom torchvision.datasets import ImageFolder\nfrom timm.models.swin_transformer import swin_base_patch4_window7_224\nfrom sklearn.metrics import classification_report, confusion_matrix, balanced_accuracy_score, accuracy_score, precision_score, recall_score, f1_score\nimport numpy as np\nfrom tqdm import tqdm\n\n# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Data Augmentation for validation\nval_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\n# Load validation dataset\nval_dataset = ImageFolder(root='/kaggle/input/misahubdataset/Dataset/validation', transform=val_transform)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n\n# Load the model (assuming it was saved with 10 classes)\nnum_classes = 10\nmodel = swin_base_patch4_window7_224(pretrained=False, num_classes=num_classes)\nmodel = model.to(device)\n\n# Load the trained model weights\nmodel.load_state_dict(torch.load('swin_transformer_best_model_in_the_world.pth', map_location=device))\n\n# Set the model to evaluation mode\nmodel.eval()\n\n# Define loss function (if you want to report validation loss, otherwise you can skip this)\ncriterion = nn.CrossEntropyLoss()\n\n# Initialize metrics storage\nall_labels = []\nall_preds = []\nrunning_val_loss = 0.0\ncorrect_val = 0\ntotal_val = 0\n\n# Evaluation loop over the validation dataset\nwith torch.no_grad():\n    val_progress = tqdm(val_loader, desc=\"Validating\")\n    for images, labels in val_progress:\n        images, labels = images.to(device), labels.to(device)\n\n        # Forward pass\n        outputs = model(images)\n\n        # Calculate loss (optional)\n        loss = criterion(outputs, labels)\n        running_val_loss += loss.item()\n\n        # Get predictions\n        _, predicted = torch.max(outputs.data, 1)\n\n        # Store all true and predicted labels\n        all_labels.extend(labels.cpu().numpy())\n        all_preds.extend(predicted.cpu().numpy())\n\n        # Calculate correct predictions for accuracy\n        total_val += labels.size(0)\n        correct_val += (predicted == labels).sum().item()\n\n# Calculate validation loss\nval_loss = running_val_loss / len(val_loader)\n\n# Calculate accuracy\nval_accuracy = 100 * correct_val / total_val\nbalanced_acc = balanced_accuracy_score(all_labels, all_preds)\n\n# Print basic accuracy metrics\nprint(f\"Validation Loss: {val_loss:.4f}\")\nprint(f\"Validation Accuracy: {val_accuracy:.2f}%\")\nprint(f\"Balanced Validation Accuracy: {balanced_acc:.4f}\")\n\n# Generate classification report\nclass_report = classification_report(all_labels, all_preds, target_names=val_dataset.classes, digits=4)\nprint(\"\\nClassification Report:\")\nprint(class_report)\n\n# Calculate and print other metrics\nprecision = precision_score(all_labels, all_preds, average='weighted')\nrecall = recall_score(all_labels, all_preds, average='weighted')\nf1 = f1_score(all_labels, all_preds, average='weighted')\noverall_acc = accuracy_score(all_labels, all_preds)\n\nprint(f\"Overall Accuracy: {overall_acc:.4f}\")\nprint(f\"Precision (weighted): {precision:.4f}\")\nprint(f\"Recall (weighted): {recall:.4f}\")\nprint(f\"F1 Score (weighted): {f1:.4f}\")\n\n# Generate confusion matrix\nconf_matrix = confusion_matrix(all_labels, all_preds)\nprint(\"\\nConfusion Matrix:\")\nprint(conf_matrix)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-24T12:55:21.120051Z","iopub.execute_input":"2024-10-24T12:55:21.120834Z","iopub.status.idle":"2024-10-24T14:48:57.607053Z","shell.execute_reply.started":"2024-10-24T12:55:21.120791Z","shell.execute_reply":"2024-10-24T14:48:57.605021Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"                                                                                 ","output_type":"stream"},{"name":"stdout","text":"Validation Loss: 0.7446, Validation Accuracy: 75.00%\nBalanced Validation Accuracy: 0.6817\nClassification Report:\n                  precision    recall  f1-score   support\n\n    Angioectasia     0.3142    0.7606    0.4447       497\n        Bleeding     0.6063    0.6435    0.6243       359\n         Erosion     0.3276    0.5584    0.4129      1155\n        Erythema     0.1460    0.5387    0.2297       297\n    Foreign Body     0.9643    0.7147    0.8209       340\nLymphangiectasia     0.7125    0.8455    0.7733       343\n          Normal     0.9899    0.7825    0.8741     12287\n           Polyp     0.4718    0.4860    0.4788       500\n           Ulcer     0.4592    0.8846    0.6045       286\n           Worms     0.9111    0.6029    0.7257        68\n\n        accuracy                         0.7500     16132\n       macro avg     0.5903    0.6817    0.5989     16132\n    weighted avg     0.8654    0.7500    0.7895     16132\n\nOverall Accuracy: 0.7500\nPrecision (weighted): 0.8654\nRecall (weighted): 0.7500\nF1 Score (weighted): 0.7895\nConfusion Matrix:\n[[ 378    0   64   32    0    1    9    7    6    0]\n [  46  231   29   41    0    4    1    7    0    0]\n [ 103   12  645  267    2    5   49   35   36    1]\n [  17    1   61  160    0    2   21   33    2    0]\n [  13    0   25   16  243    5   16    7   14    1]\n [  15    0   27    4    0  290    2    5    0    0]\n [ 572  131  979  477    7   89 9615  175  240    2]\n [  45    6  110   85    0   11    0  243    0    0]\n [   5    0   15   11    0    0    0    2  253    0]\n [   9    0   14    3    0    0    0    1    0   41]]\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"}]}]}